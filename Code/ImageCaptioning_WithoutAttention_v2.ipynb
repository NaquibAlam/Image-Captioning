{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libs/base/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import pickle, operator\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization, SpatialDropout1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, Callback\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# from wordcloud import WordCloud ,STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# import spacy\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")\n",
    "lem = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/: No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/ | wc -l\n",
    "# ! head /kaggle/input/flickr-image-dataset/flickr30k_images/results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PERC= 0.05\n",
    "VAL_PERC= 0.2\n",
    "IMAGE_SIZE= 299\n",
    "WORD_COUNT_THRESH= 5\n",
    "EMBEDDING_FILE = 'Data/crawl-300d-2M.vec'\n",
    "EMBEDDING_DIM= 300\n",
    "MAX_VOCAB_SIZE= 20000\n",
    "DENSE_HIDDEN_UNITS = 256\n",
    "LSTM_UNITS= 256\n",
    "NUM_IMGS_PER_BATCH = 10\n",
    "N_EPOCHS= 1\n",
    "INIT_LR= 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_name', ' comment_number', ' comment'], dtype='object') (158915, 3)\n",
      "Index(['image_name', 'comment_number', 'comment'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "1  1000092795.jpg              1   \n",
       "2  1000092795.jpg              2   \n",
       "3  1000092795.jpg              3   \n",
       "4  1000092795.jpg              4   \n",
       "\n",
       "                                             comment  \n",
       "0   Two young guys with shaggy hair look at their...  \n",
       "1   Two young , White males are outside near many...  \n",
       "2   Two men in green shirts are standing in a yard .  \n",
       "3       A man in a blue shirt standing in a garden .  \n",
       "4            Two friends enjoy time spent together .  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"Data/flickr30k_images/\"\n",
    "caption_df=pd.read_csv(base_dir+\"results.csv\", sep= \"|\")\n",
    "print(caption_df.columns, caption_df.shape)\n",
    "caption_df.columns= [x.strip() for x in caption_df.columns] #stripping whitesapces from column names\n",
    "caption_df[\"comment\"]= caption_df[\"comment\"].astype(str)\n",
    "print(caption_df.columns)\n",
    "caption_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_cnt= caption_df.image_name.value_counts()\n",
    "max(caption_cnt), min(caption_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above cell that all the images have 5 captions, no more no less.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31783 31783\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_images= glob.glob(base_dir+\"flickr30k_images/\"+\"*.jpg\") #This gives the entire directory for a file\n",
    "all_images_names = [x.split(\"/\")[-1] for x in all_images] #here we are extracting just the filenames\n",
    "uncommon_images= list(set(all_images_names) - set (caption_df.image_name.tolist()))\n",
    "print(len(all_images), len(caption_df.image_name.unique()))\n",
    "print(uncommon_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above cell that, there are equal number of images in both CSV and JPG folder and there are no uncommon element between these two. It shows that for all the JPG images, there are 5 captions in the csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of data pre-processing, we do the following:\n",
    "\n",
    "* convert to lowercase\n",
    "* remove punctuations\n",
    "* replace contractions with its expansions\n",
    "* remove words which have numbers in them\n",
    "* add __startseq__ and __endseq__ token for identifying start and end of the caption respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                       \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                       \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                       \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                       \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \n",
    "                       \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                       \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                       \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "                       \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\",\n",
    "                       \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \n",
    "                       \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                       \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                       \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                       \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "                       \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                       \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \n",
    "                       \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "                       \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
    "                       \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
    "                       \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
    "                       \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                       \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function contain the code for basic text cleaning.\n",
    "#since this is a text generation problem, we should not remove stopwords and do any lemmatization and stemming.\n",
    "def do_cleaning(x, contraction_map):\n",
    "    tokenizer=TweetTokenizer() #this is a robust tokenizer than just splitting on spaces.\n",
    "    x = str(x)\n",
    "    x= x.lower()\n",
    "    \n",
    "    #we are not removing apostraphes here because we have to expand these later using contraction_map.\n",
    "    for punct in \"/-\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, ' and ')\n",
    "    for punct in '?!.,\"#$%\\()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’\\n':\n",
    "        x = x.replace(punct, ' ')\n",
    "    x= re.sub(r'\\w*\\d\\w*', '', x) #remove words which have numbers in them\n",
    "    x= re.sub(r' +', r' ', x) #replace more than one space with a single space\n",
    "    x= x.strip(' ')\n",
    "    \n",
    "    words=tokenizer.tokenize(x)\n",
    "    \n",
    "    # (')aphostophe  replacement (ie)   you're --> you are  \n",
    "    # ( basic dictionary lookup : master dictionary present in a hidden block of code)\n",
    "    words=[contraction_map[word] if word in contraction_map else word for word in words]\n",
    "    # remove tokens with numbers in them\n",
    "    #after expanding contractions, for one word there could be more than one words.  that's why is nested for is used below.\n",
    "    words = [y for x in words for y in x.split(\" \") if not y.isdigit()]\n",
    "    clean_caption=\" \".join(words)\n",
    "    clean_caption= \"startseq \"+ clean_caption + \" endseq\" #add startseq and endseq in the cpations\n",
    "    clean_caption= re.sub(r\"'[a-zA-Z ]\", r'', clean_caption) #remove apostraphe which could be before whitespace or s. e.g: mohammad's naquib' room\n",
    "    return clean_caption\n",
    "\n",
    "caption_df['comment_clean']= caption_df['comment'].apply(lambda x: do_cleaning (x, contraction_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### run this cell for testing all the functionalities of do_cleaning function ###########\n",
    "# x= \"my/name: ,is, length:rope room#200 viva-voce naquib&  won't mohammad's naquib' rooom shan't we'd've alam199?!    mynaq nbhsvmjjbwd igeyu3ge675 2het ewnd ehdvdw bndehd 165naquib 887666      \"\n",
    "# do_cleaning(x, contraction_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## distribtution of length of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_df[\"comment_clean\"]= caption_df[\"comment_clean\"].str.strip()\n",
    "caption_df[\"n_chars\"]= caption_df[\"comment_clean\"].apply(len)\n",
    "caption_df[\"n_words\"]= caption_df[\"comment_clean\"].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>startseq two young guys with shaggy hair look ...</td>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>startseq two young white males are outside nea...</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>startseq two men in green shirts are standing ...</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>startseq a man in a blue shirt standing in a g...</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>startseq two friends enjoy time spent together...</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "1  1000092795.jpg              1   \n",
       "2  1000092795.jpg              2   \n",
       "3  1000092795.jpg              3   \n",
       "4  1000092795.jpg              4   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "1   Two young , White males are outside near many...   \n",
       "2   Two men in green shirts are standing in a yard .   \n",
       "3       A man in a blue shirt standing in a garden .   \n",
       "4            Two friends enjoy time spent together .   \n",
       "\n",
       "                                       comment_clean  n_chars  n_words  \n",
       "0  startseq two young guys with shaggy hair look ...       97       18  \n",
       "1  startseq two young white males are outside nea...       66       11  \n",
       "2  startseq two men in green shirts are standing ...       62       12  \n",
       "3  startseq a man in a blue shirt standing in a g...       58       12  \n",
       "4  startseq two friends enjoy time spent together...       53        8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4a0631978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize= (20,8))\n",
    "sns.distplot(caption_df[\"n_chars\"], bins=20, kde= False, ax= axes[0], color= \"red\")\n",
    "sns.distplot(caption_df[\"n_words\"], bins=20, kde= False, ax= axes[1], color= 'green')\n",
    "axes[0].set_title('Histogram for length of comments', fontsize=20, weight= 'bold')\n",
    "axes[0].set_xlabel('Length of comments', fontsize=17, weight= 'bold')\n",
    "axes[0].set_ylabel('Number of comments', fontsize=17, weight= 'bold')\n",
    "axes[0].grid(axis='y', alpha= 0.7)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=17)\n",
    "axes[1].set_xlabel('Number of words', fontsize=17, weight= 'bold')\n",
    "axes[1].set_ylabel('', fontsize=15)\n",
    "axes[1].set_title('Histogram for number of words in the comments', fontsize=20, weight= 'bold')\n",
    "axes[1].grid(axis='y', alpha= 0.7)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=17)\n",
    "\n",
    "# rects = axes[0].patches\n",
    "# bins = np.arange(0, 5500, 500)\n",
    "# bin_range= pd.cut(caption_df['n_chars'], bins= bins)\n",
    "# labels = bin_range.value_counts().values\n",
    "# for rect, label in zip(rects, labels):\n",
    "#     height = rect.get_height()\n",
    "#     axes[0].text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize= 19)\n",
    "\n",
    "    \n",
    "# rects = axes[1].patches\n",
    "# bins = np.arange(0, 1400, 150)\n",
    "# bin_range= pd.cut(caption_df['n_words'], bins= bins)\n",
    "# labels = bin_range.value_counts().values  \n",
    "# for rect, label in zip(rects, labels):\n",
    "#     height = rect.get_height()\n",
    "#     axes[1].text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize= 19)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above plots it can be seen that, most of the captions have length between 25 and 150, number of words between 5 and 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_wordcloud(text, axes, fontsize):\n",
    "#     stopwords = set(STOPWORDS)\n",
    "#     wordcloud = WordCloud(\n",
    "#                           background_color='black',\n",
    "#                           stopwords=stopwords,\n",
    "#                           max_words=2000,\n",
    "#                           collocations = False,\n",
    "#                           max_font_size=fontsize, \n",
    "#                           random_state=42\n",
    "#                          ).generate(text)\n",
    "    \n",
    "#     axes.imshow(wordcloud)\n",
    "#     plt.axis('off')\n",
    "\n",
    "# fig, axes = plt.subplots(1,1, figsize= (20,8))\n",
    "# make_wordcloud(caption_df['comment'].str.cat(sep= ' '), axes, fontsize= 20)\n",
    "# axes.set_title(\"Wordcloud of all captions\", fontsize=20, weight= 'bold')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31783, 2) Index(['image_name', 'captions'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>[startseq two young guys with shaggy hair look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>[startseq several men in hard hats are operati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>[startseq a child in a pink dress is climbing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000344755.jpg</td>\n",
       "      <td>[startseq someone in a blue shirt and hat is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000366164.jpg</td>\n",
       "      <td>[startseq two men one in a gray shirt one in a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                           captions\n",
       "0  1000092795.jpg  [startseq two young guys with shaggy hair look...\n",
       "1    10002456.jpg  [startseq several men in hard hats are operati...\n",
       "2  1000268201.jpg  [startseq a child in a pink dress is climbing ...\n",
       "3  1000344755.jpg  [startseq someone in a blue shirt and hat is s...\n",
       "4  1000366164.jpg  [startseq two men one in a gray shirt one in a..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make image to caption dictionary sort of\n",
    "# image_to_captions= caption_df.groupby(by='image_name').agg(captions= (\"comment_clean\", lambda x: x.tolist())).reset_index()\n",
    "image_to_captions= caption_df.groupby(by='image_name')['comment_clean'].agg([(\"comment_clean\", lambda x: x.tolist())]).reset_index()\n",
    "image_to_captions.rename(columns={\"comment_clean\": \"captions\"}, inplace= True)\n",
    "print(image_to_captions.shape, image_to_captions.columns)\n",
    "image_to_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TOTAL VOCABULARY SIZE:  18075\n",
      "MAX LEN OF A CAPTION:  80\n"
     ]
    }
   ],
   "source": [
    "maxlen= max(caption_df[\"n_words\"])\n",
    "vocab= np.unique(caption_df[\"comment_clean\"].str.cat(sep= ' ').split(\" \"))\n",
    "print(\"ORIGINAL TOTAL VOCABULARY SIZE: \",len(vocab))\n",
    "print(\"MAX LEN OF A CAPTION: \", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24154, 2) (6039, 2) (1590, 2)\n"
     ]
    }
   ],
   "source": [
    "#split train, val, and test data\n",
    "# image_to_captions = image_to_captions.sample(frac=1).reset_index(drop=True) #random shuffle the dataframe\n",
    "# image_to_captions.head()\n",
    "# train= image_to_captions[:24000,:]\n",
    "# val= image_to_captions[24000:30000,:]\n",
    "# test= image_to_captions.iloc[30000:, :]\n",
    "(train_val, test) = train_test_split(image_to_captions, test_size=TEST_PERC, random_state=42)\n",
    "(train, val) = train_test_split(train_val, test_size=VAL_PERC, random_state=42)\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_name):\n",
    "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
    "    img = image.load_img(base_dir+\"flickr30k_images/\"+image_name, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    # Convert PIL image to numpy array of 3-dimensions\n",
    "    img = image.img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # preprocess the images using preprocess_input() from inception module\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inception v3 model\n",
    "model = InceptionV3(weights='imagenet', input_shape = (IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "model= Model(model.input, model.layers[-2].output) #we want the output from the layer which has encoded features not from final softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a given image into a vector of size (2048, )\n",
    "start = time()\n",
    "def get_image_encoding(img_lst):\n",
    "    all_feat_vecs= []\n",
    "    for img_name in img_lst:\n",
    "        img = read_image(img_name) # preprocess the image\n",
    "        feat_vec = model.predict(img) # Get the encoding vector for the image\n",
    "        feat_vec = np.reshape(feat_vec, feat_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "        all_feat_vecs.append(feat_vec)\n",
    "    return all_feat_vecs\n",
    "\n",
    "train_img_feats= np.array(get_image_encoding(train[\"image_name\"].tolist()))\n",
    "val_img_feats= np.array(get_image_encoding(val[\"image_name\"].tolist()))\n",
    "test_img_feats= np.array(get_image_encoding(test[\"image_name\"].tolist()))\n",
    "print(\"TIME TAKEN IN SECONDS: \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bottleneck train, val, and test features to disk\n",
    "with open(\"Data/Image_encodings/encoded_train_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    pickle.dump(train_img_feats, encoded_pickle)\n",
    "with open(\"Data/Image_encodings/encoded_val_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    pickle.dump(val_img_feats, encoded_pickle)\n",
    "with open(\"Data/Image_encodings/encoded_test_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    pickle.dump(test_img_feats, encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, val and test image encodings from disk to memory\n",
    "train_img_feats = pickle.load(open(\"Data/Image_encodings/encoded_train_images.pkl\", \"rb\"))\n",
    "val_img_feats = pickle.load(open(\"Data/Image_encodings/encoded_val_images.pkl\", \"rb\"))\n",
    "test_img_feats = pickle.load(open(\"Data/Image_encodings/encoded_test_images.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VOCABULARY SIZE:  16405\n",
      "VOCABULARY SIZE AFTER FILTERING:  6767\n"
     ]
    }
   ],
   "source": [
    "train_captions= list(chain.from_iterable(train[\"captions\"].tolist()))\n",
    "train_captions_concat= \" \".join(train_captions)\n",
    "train_word_freq= dict(Counter(train_captions_concat.split(\" \")))\n",
    "train_word_freq_filtered= {word:freq for word, freq in train_word_freq.items() if freq >= WORD_COUNT_THRESH} #consider only those words which has count>=10 in train corpus\n",
    "train_word_freq_filtered = dict(sorted(train_word_freq_filtered.items(), key=operator.itemgetter(1), reverse=True)) #sort by word frequency in descending order\n",
    "vocab_train= train_word_freq_filtered.keys()\n",
    "vocab_size = len(vocab_train) + 1 # one for any unknown <'unk'> word/token\n",
    "vocab_size= min(vocab_size, MAX_VOCAB_SIZE) #taking minimum of actual and max vocab size\n",
    "print(\"ORIGINAL VOCABULARY SIZE: \", len(train_word_freq))\n",
    "print(\"VOCABULARY SIZE AFTER FILTERING: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating index to word and word to index dicts which will be used for embedding\n",
    "idxtoword = {}\n",
    "wordtoidx = {}\n",
    "\n",
    "idx = 1\n",
    "for word in vocab_train:\n",
    "    wordtoidx[word] = idx\n",
    "    idxtoword[idx] = word\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head ../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF WORDS IN EMBEDDING FILE:  2000000\n",
      "TIME TAKEN IN SECONDS:  148.79494905471802\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "start= time()\n",
    "embeddings_index = {} # empty dictionary\n",
    "f = open(EMBEDDING_FILE, encoding=\"utf-8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.strip().split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('NUMBER OF WORDS IN EMBEDDING FILE: ',len(embeddings_index))\n",
    "print(\"TIME TAKEN IN SECONDS: \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE OF EMBEDDING MATRIX:  (6767, 300)\n"
     ]
    }
   ],
   "source": [
    "#make an embedding matrix\n",
    "start= time()\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in wordtoidx.items():\n",
    "    if i >= vocab_size: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('SIZE OF EMBEDDING MATRIX: ',embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>startseq two young guys with shaggy hair look ...</td>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>startseq two young white males are outside nea...</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>startseq two men in green shirts are standing ...</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>startseq a man in a blue shirt standing in a g...</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>startseq two friends enjoy time spent together...</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "1  1000092795.jpg              1   \n",
       "2  1000092795.jpg              2   \n",
       "3  1000092795.jpg              3   \n",
       "4  1000092795.jpg              4   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "1   Two young , White males are outside near many...   \n",
       "2   Two men in green shirts are standing in a yard .   \n",
       "3       A man in a blue shirt standing in a garden .   \n",
       "4            Two friends enjoy time spent together .   \n",
       "\n",
       "                                       comment_clean  n_chars  n_words  \n",
       "0  startseq two young guys with shaggy hair look ...       97       18  \n",
       "1  startseq two young white males are outside nea...       66       11  \n",
       "2  startseq two men in green shirts are standing ...       62       12  \n",
       "3  startseq a man in a blue shirt standing in a g...       58       12  \n",
       "4  startseq two friends enjoy time spent together...       53        8  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN IN SECONDS:  2.0765249729156494\n",
      "SIZE OF EMBEDDING MATRIX:  (6767, 300)\n"
     ]
    }
   ],
   "source": [
    "#This loads embedding with exhaustive search.\n",
    "start= time()\n",
    "def make_embedding_matrix(embeddings_index, wordtoidx, vocab_size): \n",
    "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM), dtype=np.float32)\n",
    "    for word, i in wordtoidx.items():\n",
    "        #if index is larger than vocab_size then we don't have to get the embedding of this word\n",
    "        if i >= vocab_size: continue \n",
    "        #all the words in our vocab is already in lowercase\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if lowercase word is not found in embedding vector, search for uppercase word\n",
    "        embedding_vector = embeddings_index.get(word.upper())\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if lowercase or uppercase word is not found in embedding vector, search for capitalized word\n",
    "        embedding_vector = embeddings_index.get(word.capitalize())\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if still not found, search for stemmed word using Porter stemmer\n",
    "        embedding_vector = embeddings_index.get(ps.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if still not found, search for stemmed word using Lancaster stemmer\n",
    "        embedding_vector = embeddings_index.get(lc.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if still not found, search for stemmed word using Snowball stemmer\n",
    "        embedding_vector = embeddings_index.get(sb.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        # if still not found, search for lemmatized word\n",
    "        embedding_vector = embeddings_index.get(lem.lemmatize(word, \"v\"))\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector                 \n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = make_embedding_matrix(embeddings_index, wordtoidx, vocab_size)\n",
    "print(\"TIME TAKEN IN SECONDS: \", time()-start)\n",
    "print('SIZE OF EMBEDDING MATRIX: ',embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(embedding_matrix, img_feat_dim, maxlen):\n",
    "    \n",
    "    vocab_size= embedding_matrix.shape[0]\n",
    "    embedding_dim= embedding_matrix.shape[1]\n",
    "    \n",
    "    inp_img = Input(shape=(img_feat_dim,))\n",
    "    encoder_img = Dropout(0.2)(inp_img)\n",
    "    encoder_img = Dense(DENSE_HIDDEN_UNITS, activation='relu')(encoder_img)\n",
    "    inp_text = Input(shape=(maxlen,))\n",
    "#     encoder_text = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], mask_zero= True, trainable= False)(inp_text)\n",
    "    encoder_text = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable= False)(inp_text)\n",
    "    encoder_text = SpatialDropout1D(0.3)(encoder_text)\n",
    "#     encoder_text = (GRU(LSTM_UNITS, return_sequences= True))(encoder_text)\n",
    "    encoder_text = (GRU(LSTM_UNITS))(encoder_text)\n",
    "    encoder = concatenate([encoder_img, encoder_text])\n",
    "    decoder = Dense(DENSE_HIDDEN_UNITS, activation='relu')(encoder)\n",
    "    decoder = Dropout(0.2)(decoder)\n",
    "    \n",
    "    output = Dense(vocab_size, activation='softmax')(decoder)\n",
    "    model = Model(inputs = [inp_img, inp_text], outputs=output)\n",
    "    optimizer = Adam(lr= INIT_LR)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics = [\"acc\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator, intended to be used in a call to model.fit_generator()\n",
    "def data_generator(captions, img_feats, wordtoidx, max_length, num_imgs_per_batch):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n=0\n",
    "    # loop for ever over images\n",
    "    while 1:\n",
    "        for i in range(captions.shape[0]) :\n",
    "            n+=1\n",
    "            # retrieve the photo feature\n",
    "            img = img_feats[i]\n",
    "            captions_lst= captions.iloc[i,:][\"captions\"]\n",
    "            for caption in captions_lst:\n",
    "                # encode the sequence\n",
    "                seq = [wordtoidx[word] for word in caption.split(' ') if word in wordtoidx]\n",
    "                # split one sequence into multiple X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pair\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    # store\n",
    "                    X1.append(img)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            # yield the batch data\n",
    "            if n==num_imgs_per_batch:\n",
    "                yield [[np.array(X1), np.array(X2)], np.array(y)]\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### run this for testing the data_generator function ############\n",
    "# for aa in data_generator(train.iloc[:7,:], train_img_feats[:7], wordtoidx, maxlen, 3):\n",
    "#     print(aa[0][0].shape, aa[0][1].shape, aa[1].shape,  np.max(aa[0][0]), np.max(aa[0][1]), np.max(aa[1]), np.min(aa[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this callback function is used to plot the training/val accuracy and losses while training\n",
    "class TrainingPlot(Callback):\n",
    "\n",
    "    def __init__(self, filename='output/training_plot.jpg'):\n",
    "        self.filename = filename\n",
    "\n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "\n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(1, len(self.losses)+1)\n",
    "\n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn\")\n",
    "\n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            fig = plt.figure(figsize= (25,12))\n",
    "            plt.plot(N, self.losses, label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, label = \"train_acc\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_acc\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch+1))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            # Make sure there exists a folder called output in the current directory\n",
    "            # or replace 'output' with whatever direcory you want to put in the plots\n",
    "        if epoch == (N_EPOCHS -1):\n",
    "            fig.savefig(self.filename)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation\n",
    "#Both finding the optimal range of learning rates and assigning a learning rate schedule can be implemented quite trivially using Keras Callbacks.\n",
    "#Finding the optimal learning rate range\n",
    "#We can write a Keras Callback which tracks the loss associated with a learning rate varied linearly over a defined range.\n",
    "\n",
    "class LRFinder(Callback):\n",
    "    \n",
    "    '''\n",
    "    A simple callback for finding the optimal learning rate range for your model + dataset. \n",
    "    \n",
    "    # Usage\n",
    "        ```python\n",
    "            lr_finder = LRFinder(min_lr=1e-5, \n",
    "                                 max_lr=1e-2, \n",
    "                                 steps_per_epoch=np.ceil(epoch_size/batch_size), \n",
    "                                 epochs=3)\n",
    "            model.fit(X_train, Y_train, callbacks=[lr_finder])\n",
    "            \n",
    "            lr_finder.plot_loss()\n",
    "        ```\n",
    "    \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        epochs: Number of epochs to run experiment. Usually between 2 and 4 epochs is sufficient. \n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: https://arxiv.org/abs/1506.01186\n",
    "    '''\n",
    "\n",
    "    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_iterations = steps_per_epoch * epochs\n",
    "        self.iteration = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        x = self.iteration / self.total_iterations \n",
    "        return self.min_lr + (self.max_lr-self.min_lr) * x\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.iteration += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "    \n",
    "    def plot_lr(self):\n",
    "        '''Helper function to quickly inspect the learning rate schedule.'''\n",
    "        plt.plot(self.history['iterations'], self.history['lr'])\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Learning rate')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        '''Helper function to quickly observe the learning rate experiment results.'''\n",
    "        plt.plot(self.history['lr'], self.history['loss'])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning rate')\n",
    "        plt.ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            \n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2415/2416 [============================>.] - ETA: 0s - loss: 4.7740 - acc: 0.2269\n",
      "Epoch 00001: val_loss improved from inf to 4.07999, saving model to Data/Model/CheckpointModel_without_attention_5_1_5e-3.h5\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fig' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-48bd4c8bd779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m history= model.fit_generator(train_generator, validation_data= val_generator, epochs= N_EPOCHS, steps_per_epoch=steps_per_epoch, \n\u001b[0;32m---> 29\u001b[0;31m                              validation_steps= val_steps, callbacks=callbacks_list, verbose=1)\n\u001b[0m\u001b[1;32m     30\u001b[0m                             \u001b[0;31m# use_multiprocessing=True, workers=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Model/FinalModel_without_attention_5_1_5e-3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/libs/base/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/libs/base/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2211\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2213\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2214\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/libs/base/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-97bee9b899d5>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# or replace 'output' with whatever direcory you want to put in the plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'fig' referenced before assignment"
     ]
    }
   ],
   "source": [
    "start= time()\n",
    "file_path = \"Data/Model/CheckpointModel_without_attention_5_1_5e-3.h5\"\n",
    "steps_per_epoch = np.ceil(train.shape[0]/NUM_IMGS_PER_BATCH)\n",
    "val_steps= np.ceil(val.shape[0]/NUM_IMGS_PER_BATCH)\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.2, patience=2, verbose=1)\n",
    "\n",
    "lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    epochs= N_EPOCHS)\n",
    "\n",
    "schedule = SGDRScheduler(min_lr=5e-5,\n",
    "                        max_lr=1e-2,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        lr_decay=0.8,\n",
    "                        cycle_length=1,\n",
    "                        mult_factor=2)\n",
    "\n",
    "# lr_sched = [LearningRateScheduler(lambda _: init_lr * (lr_scaling_factor ** epoch))]\n",
    "plot_losses = TrainingPlot()\n",
    "callbacks_list = [checkpoint, reduce_on_plateau, schedule, plot_losses]\n",
    "model = create_model(embedding_matrix, train_img_feats.shape[1], maxlen)\n",
    "train_generator= data_generator(train, train_img_feats, wordtoidx, maxlen, NUM_IMGS_PER_BATCH)\n",
    "val_generator= data_generator(val, val_img_feats, wordtoidx, maxlen, NUM_IMGS_PER_BATCH)\n",
    "\n",
    "history= model.fit_generator(train_generator, validation_data= val_generator, epochs= N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
    "                             validation_steps= val_steps, callbacks=callbacks_list, verbose=1)\n",
    "                            # use_multiprocessing=True, workers=4)\n",
    "model.save_weights('Data/Model/FinalModel_without_attention_5_1_5e-3.h5')\n",
    "print(\"TIME TAKEN IN SECONDS: \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(embedding_matrix, train_img_feats.shape[1], maxlen)\n",
    "model.load_weights('Data/Model/CheckpointModel_without_attention_10_10_5e-3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 540s 223ms/step - loss: 4.2614 - acc: 0.2798 - val_loss: 4.0575 - val_acc: 0.2956\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr= 0.00001\n",
    "history1= model.fit_generator(train_generator, validation_data= val_generator, epochs= 1, steps_per_epoch=steps_per_epoch,\n",
    "                             validation_steps= val_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_greedySearch(photo):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(maxlen):\n",
    "        sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
    "        sequence = pad_sequences([sequence], maxlen=maxlen)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = idxtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "#         print(in_text)\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1386\n",
    "img_feat = train_img_feats[z].reshape((1,2048))\n",
    "test_img= train.iloc[z, :][\"image_name\"]\n",
    "x=plt.imread(\"Data/flickr30k_images/flickr30k_images/\"+test_img)\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "print(\"Greedy:\",predict_greedySearch(img_feat))\n",
    "test.iloc[z, :][\"captions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq a baby on the floor laughing at an older another child endseq',\n",
       " 'startseq an older sibling and a baby in the living room endseq',\n",
       " 'startseq a cute baby is smiling at another child endseq',\n",
       " 'startseq a boy looks on as a baby laughs endseq',\n",
       " 'startseq toddler playing with baby endseq']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[z, :][\"captions\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
